\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{listings}
\usepackage[T1]{fontenc}
\renewcommand\labelitemii{$\circ$}
\newcommand\tab[1][0.5cm]{\hspace*{#1}}
\title{CEMAC Documentation: UNRESP}
\begin{document}

\maketitle
\tableofcontents

\section{Python scripts}

\subsection{masaya\_conc.py}

\subsubsection{Purpose}

Used to generate an interactive Google map showing SO$_2$ concentrations around the Masaya volcano, for one output time, as predicted by the CALPUFF dispersion model.

\subsubsection{Usage}
The script should be run from a UNIX command line as follows:\\\\
\tab \texttt{\$ python3 <py-path>/masaya\_conc.py <concFile>}\\\\
where:
\begin{itemize}
\item \texttt{<py-path>} is the path (either relative to the current directory, or full) to the directory in which the python script is located (replace with “./” if it is in the current directory).
\item \texttt{<concFile>} is the path (relative or full) to the CALPUFF output file, with naming convention 'concrec******.dat' (the asterisks are replaced by numbers). This should be a single-column ASCII file (no header) containing the SO$_2$ concentrations (ug/cm$^3$) at each grid point (with the same order as the coordinates in `xy\_masaya.dat', described further below) for a particular output time.
\end{itemize}

\subsubsection{Dependencies}
The script assumes that the data file `xy\_masaya.dat' is in a sub-directory named 'Data' located directly above the directory containing the python script itself (in line with the directory structure of the git repository). This is an ASCII file with two space-separated columns of data (no header) containing the projected x and y coordinates (units: km; projection: UTM zone P16) of the computational grid used by CALPUFF.\\\\
The script also requires a number of external python packages to be imported. CEMAC periodically asks faculty (FoE) IT suppurt at the University of Leeds to add any required packaes to the loadable python/python-libs modules. Any faculty member should therefore be able to access the required packages by typing the following into the UNIX command line:\\\\
\tab \texttt{\$ module load python3}\\
\tab \texttt{\$ module load python-libs}\\\\
If the user still experiences any import errors when running the script, they should install the missing python packages themselves.

\subsubsection{Output}
Running the script successfully will generate (in the current directory):
\begin{itemize}
\item \texttt{`map\_concrec******.png'} -- A static image file of the SO$_2$ plume (with no basemap).
\item \texttt{`map\_concrec******.html'} -- An interactive webpage of the SO$_2$ plume (with a Google basemap).
\end{itemize}

\subsubsection{Algorithm details}
The python script works as follows:
\begin{itemize}
\item The spatial data file (xy\_masaya.dat) is read in, and converted to lat/lon using the utm package.
\item The concentration data file is then read in and stored into an appropriately sized 2D array.
\item Any concentrations under 20 ug/m$^3$ are `masked' so that they will appear transparent in the plots. The other concentrations are `binned' using the following limits:
\begin{itemize}
\item $C \leq 20$ (ug/m$^3$)
\item $20 < C \leq 350$
\item $350 < C \leq 600$
\item $600 < C \leq 2600$
\item $2600 < C \leq 9000$
\item $9000 < C \leq 14000$
\item $C > 14000$
\end{itemize}
Each bin is assigned a different colour from the discrete colour bar, which replicates the limits as shown on \url{http://homepages.see.leeds.ac.uk/~earunres/masayaSO2.html}.
\item The matplotlib package is used to create the static png image.
\item The gmplot package is used to create the interactive Google map plot. Each concentration data point is plotted as a cell-centred non-overlapping square using the appropriate lat/lon values and bin colour.
\end{itemize}



\subsection{3dNicaragua.py}

\subsubsection{Purpose}

Used to generate a 3D topographic plot of the area around Masaya from DEM data.

\subsubsection{Usage}
The script should be run from a UNIX command line as follows:\\\\
\tab \texttt{\$ python3 <py-path>/3dNicaragua.py <demFile>}\\\\
where:
\begin{itemize}
\item \texttt{<py-path>} is the path (either relative to the current directory, or full) to the directory in which the python script is located (replace with “./” if it is in the current directory).
\item \texttt{<demFile>} is the path (relative or full) to the DEM data file. This should be a tab delimited ASCII file with the 6 lines of metadata (ncols, nrows, xllcorner, yllcorner, cellsize, NODATA\_value) followed by a matrix of topographic heights (m) where the top-left/bottom-right heights correspond to the North-West/South-East corners of the area covered by the DEM data.
\end{itemize}

\subsubsection{Dependencies}
The script requires a number of external python packages to be imported. CEMAC periodically asks faculty (FoE) IT suppurt at the University of Leeds to add any required packaes to the loadable python/python-libs modules. Any faculty member should therefore be able to access the required packages by typing the following into the UNIX command line:\\\\
\tab \texttt{\$ module load python3}\\
\tab \texttt{\$ module load python-libs}\\\\
If the user still experiences any import errors when running the script, they should install the missing python packages themselves.

\subsubsection{Output}
Running the script successfully will launch the 3D plot in a separate window. The left and right mouse buttons can be used to rotate and zoom in/out of the plot, respectively.

\subsubsection{Algorithm details}
The python script works as follows:
\begin{itemize}
\item The DEM metadata is read in, and the lower left x and y coordinates, along with the cell size, is used to calculate the projected coordinates of each data point. These are then converted to lat/lon using the utm package, assuming a UTM zone P16 projected coordinate system (appropriate for the Masaya area of Nicaragua).
\item The DEM height data are also read in, and any `NODATA' values (measurements taken over water) are replaced with zeros.
\item The Basemap and matplotlib packages are used to plot the 3D data.
\item The `stride' parameter is hard-coded to 100 but can be reduced to increase the resolution of the plot (takes longer to execute).
\end{itemize}

\section{CALPUFF: Installation guide} \label{Installation}

\subsection{General compiler settings}
***The intel compilers are preferred***\\\\
To use the pgi compilers:
\begin{itemize}
\item Switch out the gnu compilers for the pgi compilers using: \texttt{\$ module switch gnu/native pgi/16.9}
\item Compile using: \texttt{\$ pgf90 -O0 -Kieee -Ktrap=fp -Msave <mainFortranFile>.f -o <mainFortranFile>\_pgi.exe}. These compiler flags are based on the ones given here: \url{http://www.src.com/calpuff/FAQ-answers.htm#1.1.13}. Note that the -tp flag has been removed, as the default is to build as appropriate for the current system, and the pgi library path has also been removed, since this is added to LD\_LIBRARY\_PATH by default when loading the pgi module (can confirm using `\texttt{\$ module show pgi}'. The remaining flags do the following:
\begin{itemize}
\item \texttt{\textbf{-O0}} -- Don't perform any optimisation (compilation will be fast, executable will be slow)
\item \texttt{\textbf{-Kieee}} -- Perform floating-point operations in strict conformance with the IEEE 754 standard.
\item \texttt{\textbf{-Ktrap=fp}} -- Controls the behaviour of the processor when exceptions occur. fp traps on floating point exceptions (divide by zeros, invalid operations, floating-point overflows), otherwise they would be masked and the processor would recover from the exception and continue).
\item \texttt{\textbf{-Msave}} -- Assume that all local variables are subject to the Fortran SAVE statement. (Note: this flag can greatly reduce performance, so might consider adding explicit statements only where needed in the source code to achieve speed-up?)
\end{itemize}
\end{itemize}
To use the Intel compilers:
\begin{itemize}
\item Switch out the gnu compilers for the Intel compilers using: \texttt{\$ module switch gnu/native intel/17.0.0}
\item Compile using: \texttt{\$ ifort -O0 -fltconsistency <mainFortranFile>.f -o <mainFortranFile>\_intel.exe}. It appears that the Intel compilers don't have an equivalent flag for Ktrap=fp or Msave (I think Msave behaviour is done by default through the default -auto-scalar flag).
\end{itemize}

\subsection{TERREL}
\subsubsection{Build}
To build the original source code:
\begin{itemize}
\item Download and unzip version 7.0.0 (L141010) from \url{http://www.src.com/calpuff/download/mod7_codes.htm}.
\item Convert all filenames to lowercase using: \texttt{\$ ls | while read upName; do loName=`echo "\${upName}" | tr '[:upper:]' '[:lower:]'`; mv "\$upName" "\$loName"; done}.
\item In terrel.for, delete the `flen' argument in the line "inquire(file=datafil(k),exist=lexist,flen=isize)". This is a Lahey-specific argument.
\item To get the pgi compilers to work, make the following additional changes:
\begin{itemize}
\item In terrel.for, replace the instance of `\textbackslash' with `/'.
\end{itemize}
\item To get the Intel compilers to work, make the following additional changes:
\begin{itemize}
\item In params.trl, comment out the `Lahey F95 Compiler' block and uncomment the `Compaq DF Compiler' block.
\end{itemize}
\item Compile using preferred compiler, as described above.
\end{itemize}
\subsubsection{Setup}
To set up TERREL:
\begin{itemize}
\item Make a subdirectory called `data' and put the following files inside it:
\begin{itemize}
\item w100n40.dem -- The DEM data file for Central America from the GTOPO30 dataset (downloaded via \url{http://www.src.com/calpuff/data/terrain.html}). Make sure to rename this file to the name given here if necessary.
\item (optional) xy\_masaya.dat -- This is a 2-column text file containing the x and y coordinates (in km, in the same projection as used for the main grid) of receptor points at which the terrain height will be calculated in addition to the gridded points in the main output file (only output if LXY = T in the input file).
\end{itemize}
\item Open the input file (terrel.inp) and make the following changes:
\begin{itemize}
\item NTDF -- Change to `1' (as we only have one input DEM file).
\item OUTFIL -- Change to e.g. `masaya.dat'. This is main output file that will contain the gridded processed terrain data.
\item LSTFIL -- Change to e.g. `masaya.lst'. This is essentially the log file.
\item PLTFIL -- Change to e.g. `masaya.grd'. This is an output file that can be plotted with e.g. the Surfer software package.
\item RAWECHO -- Change to e.g. `raw\_masaya.dat'. This is an output file that simply echoes the raw input DEM data but in ASCII format.
\item SAVEFIL -- Change to e.g. `masaya.sav'. This is an output binary save file that can later be used for a continuation run of TERREL (we probably don't need this).
\item XYINP -- (if LXY = T is set below) Change to `data/xy\_masaya.dat'. This is the path to the input receptor points file.
\item XYOUT -- (if LXY = T is set below) Change to e.g. `xyoutput\_masaya.rec'. This is output (elevation heights) at the receptor points.
\item LCFILES -- Set to T (true). This is a bit annoying, but all files have to have names in either full uppercase or lowercase, and I find lowercase nicer.
\item Subgroup (0b) -- At the end of this section, ensure that there is only one line that reads "1 !GTOPO30 = data/w100n40.dem !     !END!". This is the path to the DEM file.
\item LINTXY -- Set to F (false). Receptor point elevations will not be interpolated but be be the peak heights.
\item XYRADKM -- Set to 5.0. Search radius (km) for locating the peak heights at the receptor points.
\item LCOAST -- Set to F. We don't have coastline data to process.
\item LBLNREAD -- Set to F. We don't have coastline data to process.
\item LVOIDFIL -- Set to F. Don't interpolate to fill void cells. This should ensure the same behaviour as used by Sara.
\item MSHEET -- Set to 0 for now. This will ensure the same coordinate mapping as used by Sara. Consider switching back to 1 at a later date.
\item IUTMZN -- Set to 16. This is the UTM zone for Nicaragua.
\item XREFKM -- Set to 525.09417. This is the x-coordinate of the reference point (lower left corner) of the intended output grid. I think this is an easting (km) relative to the lower left corner of the UTM zone being used.
\item YREFKM -- Set to 1294.23926. This is the corresponding y-coordinate (northing).
\item NX -- Set to 91. This is the intended number of grid cells in x.
\item NY -- Set to 55. This is the intended number of grid cells in y.
\item DGRIDKM -- Set to 1.0. This is the intended grid spacing (in x and y).
\end{itemize}
\end{itemize}
\subsubsection{Run}
To run TERREL, type:\\\\
\tab \texttt{\$ ./terrel\_<compiler>.exe}

\subsection{CTGPROC}
\subsubsection{Build}
To build the original source code:
\begin{itemize}
\item Download and unzip version 7.0.0 (L150211) from \url{http://www.src.com/calpuff/download/mod7_codes.htm}.
\item Convert all filenames to lowercase using: \texttt{\$ ls | while read upName; do loName=`echo "\${upName}" | tr '[:upper:]' '[:lower:]'`; mv "\$upName" "\$loName"; done}.
\item To get the pgi compilers to work, make the following changes:
\begin{itemize}
\item In ctgproc.for, replace the instance of `\textbackslash' with `/'.
\end{itemize}
\item To get the Intel compilers to work, make the following changes:
\begin{itemize}
\item In params.ctg, comment out the `Lahey F95 Compiler' block and uncomment the `INTEL Compiler' block.
\item In control.ctg, add the missing variable `lll' to the /CONTROL/ common block.
\end{itemize}
\item Compile using preferred compiler, as described above.
\end{itemize}

\subsubsection{Setup}
To set up CTGPROC:
\begin{itemize}
\item Make a subdirectory called `data' and put the following file inside it:
nalulcl20.bil -- The `USGS Land Use/Land Cover' BIL format file for North America (Global Lambert Azimuthal), downloaded via \url{http://www.src.com/calpuff/data/land_use.html}. Note that the TIFF-format version of this data file does not work properly (alignment issues).
\item Open the input file (ctgproc.inp) and make the following changes:
\begin{itemize}
\item NDBF -- Set to 1 (we only have one input land-use file).
\item LUDAT -- Set to e.g. lulc1km\_masaya.dat. This is the main output file containing the land-use categories on the intended CALPUFF grid.
\item RUNLST -- Set to e.g. ctgproc\_masaya.lst.
\item Subgroup (0b) -- At the end of this section, ensure that there is only one line that reads "! GLAZNA  =  data/nalulcl20.bil !  !END!". This is the path to the land-use data file.
\item MESHGLAZ -- Set to 2. This will split each input grid cell (~1km) into 2x2 grid cells (each assigned the same land-use category). This ensures that there will be no CALPUFF grid cells (also 1km resolution) with missing data in them.
\item PMAP -- Set to `UTM'
\item IUTMZN -- Set to 16
\item DATUM -- Set to `WGS-84'
\item XREFKM -- Set to 525.09417
\item YREFKM -- Set to 1294.23926
\item NX -- Set to 91
\item NY -- Set to 55
\end{itemize}
\end{itemize}

\subsubsection{Run}
To run CTGPROC, type:\\\\
\tab \texttt{\$ ./ctgproc\_<compiler>.exe}\\\\
****NOTE**** PGI compiler claims that it can't find the data file, even though it is there. Can therefore only use Intel compilers at present.

\subsection{MAKEGEO}
\subsubsection{Build}
To build the original source code:
\begin{itemize}
\item Download and unzip version 3.2 (L110401) from \url{http://www.src.com/calpuff/download/mod7_codes.htm}.
\item Convert all filenames to lowercase using: \texttt{\$ ls | while read upName; do loName=`echo "\${upName}" | tr '[:upper:]' '[:lower:]'`; mv "\$upName" "\$loName"; done}.
\item In subroutine `comline' (calutils.for), comment out the call to `getcl' and uncomment the Sun compiler block (this seems to work for both the intel and pgi compilers).
\item Compile using preferred compiler, as described above.
\item ***Note*** There are a lot of warning messages with the intel compiler regarding a common block in snow.geo, however, the executable is still generated.
\end{itemize}

\subsubsection{Setup}
To set up MAKEGEO:
\begin{itemize}
\item Make a subdirectory called `data' and put the following file inside it:
\begin{itemize}
\item masaya.dat -- The terrain output file from running TERREL.
\item lulc1km\_masaya.dat -- The land-use output file from running CTGPROC.
\end{itemize}
\item Open the input file (makegeo.inp) and make the following changes:
\begin{itemize}
\item LUDAT -- Set to data/lulc1km\_masaya.dat (or whatever the path to the land-use input data file is).
\item TERRDAT -- Set to data/masaya.dat (or whatever the path to the terrain input data file is).
\item GEODAT -- Set to e.g. geo\_masaya.dat. This is the main output file that will serve as input to CALMET for the geophysical data.
\item RUNLST -- Set to e.g. geo\_masaya.lst
\item LCFILES -- Set to T to keep all filenames lowercase.
\item LSNOW -- Set to F (we don't have any snow data)
\item IUTMZN -- Set to 16
\item XREFKM -- Set to 525.09417
\item YREFKM -- Set to 1294.23926
\item NX -- Set to 91
\item NY -- Set to 55
\item Comment out (i.e. replace all occurrences of `!' with `*') the entries in subgroup 4c and 4e
\end{itemize}
\end{itemize}

\subsubsection{Run}
To run MAKEGEO, type:\\\\
\tab \texttt{\$ ./makegeo\_<compiler>.exe}

\subsection{CALETA}
There is a requirement to switch from using ECMWF GRIB data to open-source prognostic met data. This is because the ECMWF data is only free to academic institutions, and so INETER would not be able to acquire this data going forward. Work is in progress to identify an alternative data source. This will likely also require the creation of a tool to read in this data and convert it to the 3D.dat file format expected by CALMET. This is preferred over developing CALETA itself to perform this task, which is currently only able to work on particular datasets (most of which are specific to US-region-only datasets).\\\\
For completeness, below is information on how to build, setup and run CALETA for using the ECMWF GRIB files
\subsubsection{Build}
To build the original source code:
\begin{itemize}
\item Download version 3.2 (100727) from \url{http://www.src.com/calpuff/download/mod7_codes.htm} and unzip
\item To get the pgi compilers to work, open caleta.f in a text editor, navigate to subroutines `getfile\_fst' and `getfile\_ana' in turn, and replace the `/' with a `\textbackslash' in the 101 format statement.
\item Compile using preferred compiler, as described above.
\end{itemize}
****NOTE, the original caleta.f and the one supplied by IMO are markedly different (see, for example, differences in subroutine lists using \texttt{`\$ fgrep `subroutine' <path/to/orig/caleta.f -i > Orig\_caleta.txt'}, then \texttt{`\$ fgrep `subroutine' <path/to/IMO/caleta.f -i > IMO\_caleta.txt'}, then \texttt{`\$ tkdiff Orig\_caleta.txt IMO\_caleta.txt}.\\\\
To build the IMO version:
\begin{itemize}
\item Copy the files caleta.f, eta2m3d.blk and eta2m3d.cm1 from Mark's Caleta directory, and eta2m3d.par from Mark's RUN directory, into a clean directory and run the appropriate compilation command as above (ifort is preferred).
\end{itemize}

\subsubsection{Setup}
Sara's input file for Caleta (eta2m3d.inp) contains the following 8 lines:
\begin{lstlisting}
M3D file Created from ETA AWIPS 212 Grid for Falconbridge CALMET 
3  ! Flag to indicate ECMWF input data
/path/to/GRIB/files/directory/
/path/to/output/directory/
eta2m3d.lst  ! list file name
10.5,12.5  ! Range Lat
272,275  ! Range Long
1, 25  ! Vertical levels
\end{lstlisting}

\subsubsection{Run}
To run the self-built IMO version:
\begin{itemize}
\item From Mark's RUN directory, copy the files grid.dat, timestmp.dat and eta2m3d.inp into the directory. timestmp.dat contains the start date of the simulation in the format ddmmyyyy and is created after running launch\_long\_run.sh. 
\item Run caleta using:\\\\
\tab \texttt{\$ ./caleta\_<compiler>.exe}
\end{itemize}
***NOTE: This gives an output file (out\_caleta.m3d) that is different to the one in Mark's RUN directory. Specifically, the new file has non-zero terrain heights where Mark has all zeros, and also some zeros for sea-level-pressure and bad output (*****) for precipitation. This causes issues in the next step (CALMET). Running the IMO-built version (the "caleta\_masaya" executable in the EXEC directory) on the same input files produces a valid out\_caleta.m3d file; this suggests that the code in Mark's Caleta directory is somehow different to the code used to build the Caleta executable in the EXEC directory.

\subsection{CALMET}
\subsubsection{Build}
To build the original source code:
\begin{itemize}
\item Download version 6.5.0 (150223) from \url{http://www.src.com/calpuff/download/mod7_codes.htm} and unzip. Create a temporary directory, cd into it, and unzip the second file inside. Copy CALMET.INP from this temporary directory into the main unzipped directory, and then delete the temporary directory.
\item Convert all filenames to lowercase using: \texttt{\$ ls | while read upName; do loName=`echo "\${upName}" | tr '[:upper:]' '[:lower:]'`; mv "\$upName" "\$loName"; done}.
\item In params.met, change mxnz from 12 to 27 and mxnzi from 12 to 50.
\item Compile using preferred compiler, as described above.
\end{itemize}

\subsubsection{Setup}
To set up CALMET:
\begin{itemize}
\item Make a subdirectory called `data' and put the following file inside it:
\begin{itemize}
\item geo\_masaya.dat -- The output file from running MAKEGEO.
\item out\_caleta.m3d -- The output file from running CALETA.
\end{itemize}
\item Fix the apparent issue in the out\_caleta.m3d file -- In the first surface data-block, replace the latitudes and longitudes of the first few points in the extraction subdomain to match all the other surface data-blocks.
\item Open the input file (calmet.inp) and make the following changes:
\begin{itemize}
\item GEODAT -- Set to data/geo\_masaya.dat.
\item LCFILES -- Set to T
\item NUSTA -- Set to 0 (we don't have any upper-air stations)
\item NOWSTA -- Set to 0 (we don't have any overwater stations)
\item UPDAT -- Comment out all three lines (we don't have upper air data)
\item SEADAT -- Comment out (we don't have overwater stations data)
\item M3DDAT -- Set to data/out\_caleta.m3d
\item IBYR, IBMO, IBDY, IBHR -- Set to required simulation start date/time (e.g. 2017, 12, 04, 0)
\item IEYR, IEMO, IEDY, IEHR -- Set to required simulation end date/time (e.g. 2017, 12, 06, 0)
\item ABTZ -- Set to UTC+0000 (we want times in UTC)
\item LCALGRD -- Set to F (don't compute special data fields)
\item IUTMZN -- Set to 16
\item DATUM -- Set to WGS-84
\item NX -- Set to 91
\item NY -- Set to 55
\item XORIGKM -- Set to 525.09417
\item YORIGKM -- Set to 1294.23926
\item NZ -- Set to 24
\item ZFACE -- Set to "0, 20, 60, 140, 260, 540, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000". These are the heights of the output grid
\item NOOBS -- Set to 2 (use 3D data for surface, overwater and upper air data)
\item NSSTA -- Set to 0 (no surface stations)
\item NPSTA -- Set to -1 (flag to use 3D precip data)
\item MCLOUD -- Set to 4 (use prognostic 3D RH fields to get gridded cloud cover at all levels)
\item BIAS -- Set to 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 (i.e. zero bias at each Z level)
\item IPROG -- Set to 14 (i.e. use 3D winds as initial guess field)
\item ISTEPPGS -- Set to 10800 (timestep of the prognostic met model) ***This was set to 3 in Mark's input file, but this caused an error for me, plus 10800 seems correct.***
\item RMAX1-RMAX3 -- Set all to 5.0 (radii of influence in km for stations)
\item RPROG -- Set to 1.0 (weighting parameter of the 3D data).
\item NSMTH -- Set to 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4 ,4 (number of passes in the smoothing procedure for each Z level)
\item NINTR2 -- (not needed?) Set to 5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5 (max stations used per Z level for interpolation)
\item FEXTR2 -- (not needed?) Set to 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 (not used but need NZ values)
\item ISURFT -- Set to -2 (use domain-average prognostic lapse rate)
\item IUPT -- Set to -2 (use domain-average prognostic lapse rate)
\item ZUPT -- Set to 100. (depth through which the domain-scale lapse rate is computed)
\item IMIXH -- Set to 2 (Batchvarova and Gryning mixing height method used over all surfaces)
\item DZZI -- Set to 300. (depth, m, of layer above current convective mixing height through which lapse rate is computed)
\item ZIMIN -- Set to 250. (minimum overland mixing height)
\item ITPROG -- Set to 1 (use prognostic RH)
\item ITPROG -- Set to 2 (no surface or upper-air temperature observations; use 3D data).
\end{itemize}
\end{itemize}

\subsubsection{Run}
To run CALMET, type:\\\\
\tab \texttt{\$ ./calmet\_<compiler>.exe}


\subsection{CALPUFF}
\subsubsection{Build}
To build the original source code:
\begin{itemize}
\item Download version 7.2.1 (150618) from \url{http://www.src.com/calpuff/download/mod7_codes.htm} and unzip
\item Convert all filenames to lowercase using: \texttt{\$ ls | while read upName; do loName=`echo "\${upName}" | tr '[:upper:]' '[:lower:]'`; mv "\$upName" "\$loName"; done}.
\item In params.puf, change mxnz from 12 to 27 and mxrec from 10000 to 20000.
\item In calpuff.for, near the end of subroutine `comp' (e.g. just after the call to FOGOUT), insert the following lines of code to write out the hourly concentrations to individual files:\\
\begin{lstlisting}
         do ispec=1,nspec
         write(infile,10000) ispec, nn
10000    format('concrec',I2.2,I4.4,'.dat')
         open(50,file=infile)
          do i=1,nrec
          write(50,*) chirec(i,ispec)
          end do
         end do
         close(50)
\end{lstlisting}
Also add `character*150 infile' to the declarations of this subroutine.
\item Build in two stages. For intel compilers:\\
\tab \texttt{\$ ifort -c modules.for}\\
\tab \texttt{\$ ifort -O0 -fltconsistency calpuff.for modules.o -o calpuff.exe}
\end{itemize}

\subsubsection{Setup}
To set up CALPUFF:
\begin{itemize}
\item Make a subdirectory called `data' and put calmet.dat (the output file from CALMET) inside it
\item Rename the input file from calpuff\_v7.inp to calpuff.inp, open it, and make the following changes:
\begin{itemize}
\item METDAT -- Change to data/calmet.dat
\item RSTARTE -- Uncomment and set to restart\_so2\_e.dat. This is the name given to the generated restart file at simulation end.
\item OZDAT -- Comment out
\item DEBUG -- Uncomment and set to debug.dat (we want an output debug file)
\item BALDAT -- Uncomment and set to massbal.dat (we want an output mass balance file)
\item LCFILES -- Set to T
\item IBYR, IBMO, IBDY, IBHR -- Set to required simulation start date/time (e.g. 2017, 12, 04, 0)
\item IEYR, IEMO, IEDY, IEHR -- Set to required simulation end date/time (e.g. 2017, 12, 06, 0)
\item ABTZ -- Set to UTC+0000 (we want times in UTC) 
\item NSPEC -- Set to 2 (we have SO2 and SO4)
\item NSE -- Set to 1 (only one species actually emitted; SO4 is created in the atmosphere)
\item MRESTART -- Set to 2 for main run (i.e. write a restart file at the end of the run)
\item MTRANS -- Set to 0 (don't model transitional plume rise)
\item MTIP -- Set to 0 (don't model stack downwash)
\item MBDW -- (not needed?) Set to 2 (use PRIME building downwash method)
\item MSHEAR -- Set to 1 (vertical wind shear modelled)
\item MCHEM -- Set to 1 (use MESOPUFF II cheical scheme)
\item MWET -- Set to 0 (don't model wet removal)
\item MPARTL -- Set to 0 (don't model partial plume penetration)
\item MPARTLBA -- Set to 0 (don't model partial plume penetration)
\item CSPEC -- Delete all but SO2 and SO4 from both the list and the table
\item IUTMZN -- Set to 16
\item DATUM -- Set to WGS-84
\item NX -- Set to 91
\item NY -- Set to 55
\item NZ -- Set to 24
\item ZFACE -- Set to "0,20,60,140,260,540,1000,2000,3000,4000,5000,6000,7000, 8000,9000,10000,11000,12000,13000,14000,15000,16000,17000,18000,19000"
\item XORIGKM -- Set to 525.09417
\item YORIGKM -- Set to 1294.23926
\item IECOMP -- Set to 91 (X index of UR corner)
\item JECOMP -- Set to 55 (J index of UR corner)
\item LSAMP -- Set to F (no gridded receptors)
\item IDRY -- Set to 0 (no dry fluxes output)
\item IWET -- Set to 0 (no wet fluxes output)
\item IVIS -- Set to 0 (no RH output)
\item LCOMPRS -- Set to F (no compression to output file)
\item IPFTRAK -- Set to 0 (no puff-tracking output)
\item INRISE -- Set to 1 (create plume properties output file rise.dat)
\item ICFRQ -- Set to 24 (concentration print interval in timesteps)
\item IPRTU -- Set to 1 (use g/m3 for printing)
\item SPECIES LIST -- Delete all but SO2 and SO4, and set both to "1, 1, 0, 0, 0, 0, 0" (just print and save concentrations)
\item LDEBUG -- Set to T (debug output wanted) ***NOTE: Set this to F to dramatically reduce .lst file size***
\item NPFDEB -- Set to 1044 (track this many puffs in debug)
\item NN2 -- Set to 24 (stop debug output after this number of timesteps)
\item XHILL2M -- (not needed?) Set to 0 (factor to convert horizontal dimensions to meters if MHILL is 1)
\item ZHILL2M -- (not needed?) Set to 0 (factor to convert vertical dimensions to meters if MHILL is 1)
\item INPUT GROUP 7 -- (not needed?) Delete all but SO2 line
\item INPUT GROUP 8 -- (not needed?) Delete all but SO4 line
\item INPUT GROUP 10 -- (not needed?) Delete all but SO2 line, and change liquid precip to 2.61E-05 and frozen precip to 3.0E-05
\item MOZ -- Set to 0 (use monthly background ozone value)
\item BCKO3 -- Set all values to 30 (monthly background ozone)
\item BCKNH3 -- Set all values to 1.0 (monthly background ammonia)
\item XMXLEN -- Set to 0.5 (maximum length of a slug)
\item NCOUNT -- Set to 5 (number of iterations when computing transport wind)
\item SZCAP\_M -- Set to -1.0 (disable)
\item WSCALM -- Set to 0.01 (minimum wind speed for non-calm conditions)
\item XMINZI -- Set to 20.0 (minimum mixing height)
\item SL2PF -- Set to 5.0 (slug-to-puff transition criterion factor)
\item SYSPLITH -- Set to 0.8 (min sig-y before split)
\item SHSPLITH -- Set to 1.0 (min puff elongation rate before split)
\item RSAMPBC -- Set to 15.0 (search radius for sampling nearest BC puff)
\item MDEPBC -- Set to 0 (no adjustment for depletion)
\item NPT1 -- Set to 0 (no point sources to follow)
\item NSPT1 -- Set to 0 (no variable emissions factors)
\item Subgroup 13b -- Delete all sources
\item Subgroup 13d -- Delete all sources
\item NAR1 -- Set to 1 (one area source to follow)
\item Subgroup 14b -- Add following lines (source parameters):\\
\tab ! SRCNAM = MASAYA2 !\\
\tab ! X = 0, 520, 50, 0.004 !\\
\tab !END!
\item Subgroup 14c -- Add following lines (source coordinates): \\
\tab 1 ! SRCNAM = MASAYA2 !\\
\tab 1 ! XVERT = 590.495, 590.740, 590.702, 590.435!  \\
\tab 1 ! YVERT = 1324.876, 1324.831, 1325.058, 1325.078!\\
\tab !END!
\item NREC -- Set to 18000 (number of non-gridded receptor points to follow)
\item NRGRP -- Set to 0 (no groups of receptors)
\item Subgroup 20b -- Delete all groups
\item Subgroup 20c -- Paste in 18000 non-gridded receptor points from Sara's input file.

\end{itemize}
\end{itemize}

\subsubsection{Run}
To run CALMET, type:\\
\tab \texttt{\$ ./calpuff\_<compiler>.exe}\\\\
Modify calpuff.inp so the the restart flag (RESTARTB) is set to 0 and run again.

\section{Forecasting System - Leeds}
This section describes the processes and file/directory structure behind the automated forecasting system, as run at Leeds.\\\\
The root directory is called `UNRESPForecastingSystem' and is under version control on GitHub (\url{https://github.com/cemac-tech/UNRESPForecastingSystem.git}). The file/directory structure below this is described below:
\begin{itemize}
\item Run.sh -- The main shell script that runs the entire forecasting system
\item CALPUFF\_SRC/ -- Fortran source code for the various parts of the CALPUFF modelling system (as listed below). This source data corresponds to Version 7 of the CALPUFF system (downloadable from here: \url{http://www.src.com/calpuff/download/mod7_codes.htm}), with a few minimal code changes required to allow the model to be built on a Linux system with Intel compilers; these changes are described in section \ref{Installation}.
\begin{itemize}
\item /TERREL -- Combines and grids terrain data
\item /CTGPROC -- Processes and grids land use data
\item /MAKEGEO -- Merges land use and terrain data to produce the geophysical data file for CALMET
\end{itemize}
\item CALPUFF\_INP/ -- Control files for the various elements of the CALPUFF system. All parameters that have been modified from those in the original downloaded file are described in \ref{Installation}.
\item CALPUFF\_EXE/ -- Executables for the various elements of the CALPUFF system.
\item data/ -- Various input data files to the CALPUFF system, as described below:
\begin{itemize}
\item w100n40.dem -- The (renamed) DEM data file for Central America from the GTOPO30 dataset (downloaded via \url{http://www.src.com/calpuff/data/terrain.html}).
\item nalulcl20.bil -- The `USGS Land Use/Land Cover' file for North America (downloaded via \url{http://www.src.com/calpuff/data/land_use.html}).
\item TERREL and CTGPROC output (.dat) files as input to MAKEGEO (copied into directory during runtime)
\end{itemize}
\end{itemize}


\end{document}